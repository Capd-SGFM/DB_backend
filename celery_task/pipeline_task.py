# celery_task/pipeline_task.py
from __future__ import annotations

import time
import uuid

import httpx
from celery import group
from loguru import logger
from sqlalchemy.dialects.postgresql import insert
from sqlalchemy import select

from . import celery_app
from . import websocket_task
from .rest_api_task import backfill_symbol_interval

from db_module.connect_sqlalchemy_engine import SyncSessionLocal
from models import CryptoInfo
from models.pipeline_state import (
    is_pipeline_active,
    set_component_active,
    PipelineComponent,
)
from models.backfill_progress import BackfillProgress

__all__ = ["start_pipeline", "stop_pipeline", "run_maintenance_cycle"]


# ================================================================
#  1) ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹œì‘
# ================================================================
@celery_app.task(name="pipeline.start_pipeline")
def start_pipeline():
    logger.info("[pipeline.start_pipeline] íŒŒì´í”„ë¼ì¸ ì‹œì‘")

    if not is_pipeline_active():
        logger.info("[pipeline.start_pipeline] pipeline_state.id=1 ì´ OFFë¼ì„œ ì¢…ë£Œ")
        return

    # -----------------------------
    # 1) WebSocket ì—”ì§„ ì‹œì‘
    # -----------------------------
    set_component_active(PipelineComponent.WEBSOCKET, True)
    websocket_task.websocket_collector.delay()
    logger.info("[pipeline.start_pipeline] WebSocket collector started.")

    # WebSocket ì•ˆì •í™”ë¥¼ ìœ„í•´ 30ì´ˆ ëŒ€ê¸°
    time.sleep(30)

    if not is_pipeline_active():
        logger.info("[pipeline.start_pipeline] OFF ê°ì§€ â†’ Backfill ìƒëµ")
        set_component_active(PipelineComponent.WEBSOCKET, False)
        return

    # -----------------------------
    # 2) Binance serverTime ì¡°íšŒ
    # -----------------------------
    try:
        with httpx.Client(timeout=10.0) as client:
            res = client.get("https://fapi.binance.com/fapi/v1/time")
            res.raise_for_status()
            server_time_ms = res.json()["serverTime"]
    except Exception as e:
        logger.error(f"[pipeline.start_pipeline] serverTime ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return

    ws_frontier_ms = int(server_time_ms)
    logger.info(f"[pipeline.start_pipeline] ws_frontier_ms={ws_frontier_ms}")

    # -----------------------------
    # 3) Backfill ì‹œì‘
    # -----------------------------
    set_component_active(PipelineComponent.BACKFILL, True)

    backfill_run_id = f"pipeline-{uuid.uuid4().hex}"
    logger.info(f"[pipeline.start_pipeline] Backfill run_id={backfill_run_id}")

    # -----------------------------
    # DBì—ì„œ ì‹¬ë³¼ ê°€ì ¸ì˜¤ê¸°
    # -----------------------------
    with SyncSessionLocal() as session:
        symbols = (
            session.query(CryptoInfo.symbol, CryptoInfo.pair)
            .filter(CryptoInfo.pair.isnot(None))
            .all()
        )

    # âš  í…ŒìŠ¤íŠ¸ìš© interval ê°•ì œ ì§€ì •
    intervals = ["1h", "4h", "1d", "1w", "1M"]

    if not symbols:
        logger.error("[pipeline.start_pipeline] ì‹¬ë³¼ ì—†ìŒ â†’ ì¢…ë£Œ")
        return

    # -----------------------------
    # Dummy row ìƒì„± (ëª¨ë“  interval)
    # -----------------------------
    first_symbol = symbols[0].symbol
    with SyncSessionLocal() as session, session.begin():
        for interval in intervals:
            stmt = (
                insert(BackfillProgress)
                .values(
                    run_id=backfill_run_id,
                    symbol=first_symbol,
                    interval=interval,
                    state="PENDING",
                    pct_time=0.0,
                    last_candle_ts=None,
                    last_error=None,
                )
                .on_conflict_do_nothing()
            )
            session.execute(stmt)

    logger.info("[pipeline.start_pipeline] Dummy rows inserted for all intervals")

    # -----------------------------
    # Backfill ì „ì²´ ì‘ì—… ìƒì„±
    # -----------------------------
    jobs = []
    for row in symbols:
        for interval in intervals:
            jobs.append(
                backfill_symbol_interval.s(
                    symbol=row.symbol,
                    pair=row.pair,
                    interval=interval,
                    ws_frontier_ms=ws_frontier_ms,
                    run_id=backfill_run_id,
                )
            )

    if not jobs:
        logger.warning("[pipeline.start_pipeline] Backfill job ì—†ìŒ")
        return

    # -----------------------------
    # Backfill ê·¸ë£¹ ì‹¤í–‰
    # -----------------------------
    group_result = group(jobs).apply_async()
    logger.info("[pipeline.start_pipeline] Backfill group started")

    # ì™„ë£Œë  ë•Œê¹Œì§€ Polling
    while not group_result.ready():
        if not is_pipeline_active():
            logger.info("[pipeline.start_pipeline] OFF ê°ì§€ â†’ Backfill ì¤‘ë‹¨")
            try:
                group_result.revoke(terminate=True)
            except Exception:
                pass
            break
        time.sleep(3)

    set_component_active(PipelineComponent.BACKFILL, False)
    logger.info("[pipeline.start_pipeline] Backfill group finished")

    # -----------------------------
    # Backfill ì „ì²´ ì„±ê³µ ì—¬ë¶€ í™•ì¸
    # -----------------------------
    with SyncSessionLocal() as session:
        failures = (
            session.execute(
                select(BackfillProgress).where(
                    BackfillProgress.run_id == backfill_run_id,
                    BackfillProgress.state == "FAILURE",
                )
            )
            .scalars()
            .all()
        )

    if failures:
        logger.error(
            "[pipeline.start_pipeline] Backfill ì‹¤íŒ¨ ë°œìƒ â†’ Maintenance ì§„ì… ì°¨ë‹¨"
        )
        return

    logger.info("[pipeline.start_pipeline] Backfill ì „ì²´ SUCCESS â†’ Maintenanceë¡œ ì´ë™")

    # -----------------------------------------
    # 4) ìœ ì§€ë³´ìˆ˜ ë£¨í”„ ì‹œì‘
    # -----------------------------------------
    run_maintenance_cycle.delay()
    logger.info("[pipeline.start_pipeline] Maintenance cycle started.")


# ================================================================
#  2) íŒŒì´í”„ë¼ì¸ ì •ì§€
# ================================================================
@celery_app.task(name="pipeline.stop_pipeline")
def stop_pipeline():
    logger.info("[pipeline.stop_pipeline] íŒŒì´í”„ë¼ì¸ ì •ì§€")
    return


# ================================================================
#  3) Backfill í›„ REST â†” Indicator ë¬´í•œ ë°˜ë³µ ë£¨í”„
# ================================================================
@celery_app.task(name="pipeline.run_maintenance_cycle")
def run_maintenance_cycle():
    logger.info("[pipeline] Maintenance cycle started")

    from .rest_maintenance_task import run_maintenance_cycle as rest_cycle
    from .indicator_task import update_last_indicator_for_symbol_interval as ind_cycle

    while is_pipeline_active():

        # ğŸ”µ REST ìœ ì§€ë³´ìˆ˜
        logger.info("[pipeline] REST maintenance ì‹œì‘")
        set_component_active(PipelineComponent.REST_MAINTENANCE, True)

        rest_job = rest_cycle.delay()
        while not rest_job.ready():
            if not is_pipeline_active():
                set_component_active(PipelineComponent.REST_MAINTENANCE, False)
                return
            time.sleep(2)

        set_component_active(PipelineComponent.REST_MAINTENANCE, False)
        logger.info("[pipeline] REST maintenance ì™„ë£Œ")

        # ğŸŸ¡ ë³´ì¡°ì§€í‘œ ê³„ì‚°
        logger.info("[pipeline] Indicator ê³„ì‚° ì‹œì‘")
        set_component_active(PipelineComponent.INDICATOR, True)

        ind_job = ind_cycle.delay()
        while not ind_job.ready():
            if not is_pipeline_active():
                set_component_active(PipelineComponent.INDICATOR, False)
                return
            time.sleep(2)

        set_component_active(PipelineComponent.INDICATOR, False)
        logger.info("[pipeline] Indicator ê³„ì‚° ì™„ë£Œ")

        time.sleep(1)

    logger.info("[pipeline] Maintenance cycle stopped (pipeline OFF)")
